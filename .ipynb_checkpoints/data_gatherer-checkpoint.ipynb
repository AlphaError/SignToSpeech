{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acfc326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPurpose: take in a video at a certain directory and product a series of images to be fed into the learning \\ninterval of video - hyperparameter\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: take in a video at a certain directory and product a series of images to be fed into the learning \n",
    "interval of video - hyperparameter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4faefb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0ee496e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching through video: /Users/korahughes/Documents/GitHub/SignToSpeech/src-videos/A-test.mov\n",
      "processing images from video 1 with 58.74125874125874 fps\n",
      "frame 0 saved into Avideo1-image1.png\n",
      "frame 15 saved into Avideo1-image2.png\n",
      "frame 30 saved into Avideo1-image3.png\n",
      "frame 45 saved into Avideo1-image4.png\n",
      "frame 60 saved into Avideo1-image5.png\n",
      "frame 75 saved into Avideo1-image6.png\n",
      "frame 90 saved into Avideo1-image7.png\n",
      "frame 105 saved into Avideo1-image8.png\n",
      "frame 120 saved into Avideo1-image9.png\n",
      "frame 135 saved into Avideo1-image10.png\n",
      "frame 150 saved into Avideo1-image11.png\n",
      "frame 165 saved into Avideo1-image12.png\n",
      "frame 180 saved into Avideo1-image13.png\n",
      "frame 195 saved into Avideo1-image14.png\n",
      "frame 210 saved into Avideo1-image15.png\n",
      "frame 225 saved into Avideo1-image16.png\n",
      "frame 240 saved into Avideo1-image17.png\n",
      "frame 255 saved into Avideo1-image18.png\n",
      "frame 270 saved into Avideo1-image19.png\n",
      "frame 285 saved into Avideo1-image20.png\n",
      "frame 300 saved into Avideo1-image21.png\n",
      "frame 315 saved into Avideo1-image22.png\n",
      "frame 330 saved into Avideo1-image23.png\n",
      "frame 345 saved into Avideo1-image24.png\n",
      "frame 360 saved into Avideo1-image25.png\n",
      "frame 375 saved into Avideo1-image26.png\n",
      "frame 390 saved into Avideo1-image27.png\n",
      "frame 405 saved into Avideo1-image28.png\n",
      "Video 1 returned 28 images from 417 frames.\n",
      "\n",
      "searching through video: /Users/korahughes/Documents/GitHub/SignToSpeech/src-videos/B-test.mov\n",
      "processing images from video 2 with 58.28125 fps\n",
      "frame 0 saved into Bvideo2-image1.png\n",
      "frame 15 saved into Bvideo2-image2.png\n",
      "frame 30 saved into Bvideo2-image3.png\n",
      "frame 45 saved into Bvideo2-image4.png\n",
      "frame 60 saved into Bvideo2-image5.png\n",
      "frame 75 saved into Bvideo2-image6.png\n",
      "frame 90 saved into Bvideo2-image7.png\n",
      "frame 105 saved into Bvideo2-image8.png\n",
      "frame 120 saved into Bvideo2-image9.png\n",
      "frame 135 saved into Bvideo2-image10.png\n",
      "frame 150 saved into Bvideo2-image11.png\n",
      "frame 165 saved into Bvideo2-image12.png\n",
      "frame 180 saved into Bvideo2-image13.png\n",
      "frame 195 saved into Bvideo2-image14.png\n",
      "frame 210 saved into Bvideo2-image15.png\n",
      "frame 225 saved into Bvideo2-image16.png\n",
      "frame 240 saved into Bvideo2-image17.png\n",
      "frame 255 saved into Bvideo2-image18.png\n",
      "frame 270 saved into Bvideo2-image19.png\n",
      "frame 285 saved into Bvideo2-image20.png\n",
      "frame 300 saved into Bvideo2-image21.png\n",
      "frame 315 saved into Bvideo2-image22.png\n",
      "frame 330 saved into Bvideo2-image23.png\n",
      "frame 345 saved into Bvideo2-image24.png\n",
      "frame 360 saved into Bvideo2-image25.png\n",
      "Video 2 returned 25 images from 370 frames.\n",
      "\n",
      "\n",
      "...done :)\n"
     ]
    }
   ],
   "source": [
    "vid_dir = \"/src-videos/\"\n",
    "img_dir = \"/test-images/\"\n",
    "\n",
    "def main():\n",
    "    # get images\n",
    "    cwd = os.getcwd()  # current dir\n",
    "    videos = [cwd+vid_dir+file for file in os.listdir(cwd+vid_dir) if '.mov' in file]  # list of videos via dir string\n",
    "#     assert len(videos) >= 1\n",
    "    \n",
    "    fps = 4  # desired frames per second approximately\n",
    "    i = 1\n",
    "    # first letter of the file should be what category it is (used for the data processing in SignToSpeech file)\n",
    "    letters = [\"A\", \"B\"]  # hyperparameter for what letter we are looking at (known as of vid recording)\n",
    "    # make folder\n",
    "    for vid in videos:\n",
    "        print(\"searching through video:\", vid)\n",
    "        image_name = \"video\" + str(i) + \"-image\"\n",
    "        vidcap = cv2.VideoCapture(vid)  # init video\n",
    "#         vidcap.set(cv2.CAP_PROP_FPS, fps)  # set frames\n",
    "        rate = round(vidcap.get(cv2.CAP_PROP_FPS)/fps)  # actual fps/desired fps = rate of capture of our video\n",
    "        success, image = vidcap.read()\n",
    "        count = 0  # count of elapsed frames\n",
    "        rate_count = 0  # count of pictures taken\n",
    "        while success:\n",
    "            if count == 0:\n",
    "                print(\"processing images from video\", i, \"with\", vidcap.get(cv2.CAP_PROP_FPS), \"fps\")\n",
    "            if count%rate == 0:\n",
    "                rate_count += 1\n",
    "                cv2.imwrite((cwd+img_dir+letters[i-1]+image_name+str(rate_count)+\".png\"), image) # save frame as png file \n",
    "                print(\"frame\", count, \"saved into\", (letters[i-1]+image_name+str(rate_count)+\".png\"))\n",
    "            success, image = vidcap.read()\n",
    "#           print('Read a new frame: ', success)\n",
    "            count += 1\n",
    "        print(\"Video\", i, \"returned\", rate_count, \"images from\", count, \"frames.\")\n",
    "        i += 1\n",
    "        print()\n",
    "        \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"\\n...done :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba337fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
